# Databricks Cluster Configuration for Ray on Spark

# CPU-based cluster configuration
cpu_cluster:
  cluster_name: "ray-cpu-cluster"
  spark_version: "13.3.x-scala2.12"
  node_type_id: "i3.2xlarge"  # AWS
  # node_type_id: "Standard_D8s_v3"  # Azure
  # machine_type_id: "n2-standard-8"  # GCP
  
  driver_node_type_id: "i3.2xlarge"
  
  autoscale:
    min_workers: 2
    max_workers: 8
  
  spark_conf:
    "spark.databricks.delta.preview.enabled": "true"
    "spark.sql.adaptive.enabled": "true"
    "spark.sql.adaptive.coalescePartitions.enabled": "true"
  
  custom_tags:
    project: "ray-ml-pipeline"
    team: "data-science"
    cost_center: "ml-infrastructure"
  
  # Ray-specific configuration
  ray:
    num_worker_nodes: 4
    num_cpus_per_node: 4
    num_gpus_per_node: 0
    object_store_memory_per_node: 10_000_000_000  # 10GB

# GPU-based cluster configuration
gpu_cluster:
  cluster_name: "ray-gpu-cluster"
  spark_version: "13.3.x-gpu-ml-scala2.12"
  node_type_id: "g4dn.xlarge"  # AWS - 1 GPU, 4 CPUs
  # node_type_id: "Standard_NC6s_v3"  # Azure
  # machine_type_id: "n1-standard-4-nvidia-tesla-t4"  # GCP
  
  driver_node_type_id: "i3.xlarge"
  
  autoscale:
    min_workers: 1
    max_workers: 4
  
  spark_conf:
    "spark.databricks.delta.preview.enabled": "true"
    "spark.sql.adaptive.enabled": "true"
  
  init_scripts:
    - "dbfs:/scripts/install_nccl.sh"  # For multi-GPU training
  
  custom_tags:
    project: "ray-ml-pipeline"
    team: "data-science"
    gpu_enabled: "true"
  
  # Ray-specific configuration
  ray:
    num_worker_nodes: 4
    num_cpus_per_node: 2
    num_gpus_per_node: 1
    object_store_memory_per_node: 15_000_000_000  # 15GB

# Small development cluster
dev_cluster:
  cluster_name: "ray-dev-cluster"
  spark_version: "13.3.x-scala2.12"
  node_type_id: "i3.xlarge"
  
  num_workers: 2
  
  spark_conf:
    "spark.databricks.delta.preview.enabled": "true"
  
  custom_tags:
    project: "ray-ml-pipeline"
    environment: "development"
  
  # Ray-specific configuration
  ray:
    num_worker_nodes: 2
    num_cpus_per_node: 2
    num_gpus_per_node: 0
    object_store_memory_per_node: 5_000_000_000  # 5GB

# Production cluster with high availability
production_cluster:
  cluster_name: "ray-production-cluster"
  spark_version: "13.3.x-scala2.12"
  node_type_id: "i3.4xlarge"
  
  driver_node_type_id: "i3.4xlarge"
  
  autoscale:
    min_workers: 4
    max_workers: 16
  
  autotermination_minutes: 0  # Never auto-terminate
  
  spark_conf:
    "spark.databricks.delta.preview.enabled": "true"
    "spark.sql.adaptive.enabled": "true"
    "spark.databricks.io.cache.enabled": "true"
  
  custom_tags:
    project: "ray-ml-pipeline"
    environment: "production"
    sla: "high"
  
  # Ray-specific configuration
  ray:
    num_worker_nodes: 8
    num_cpus_per_node: 8
    num_gpus_per_node: 0
    object_store_memory_per_node: 20_000_000_000  # 20GB

# Recommended libraries to install
libraries:
  pypi:
    - ray[default]==2.9.0
    - ray[data]==2.9.0
    - ray[train]==2.9.0
    - ray[tune]==2.9.0
    - xgboost==2.0.3
    - torch==2.1.0
    - torchvision==0.16.0
    - hyperopt==0.2.7
    - optuna==3.5.0
  
  maven:
    - coordinates: "io.delta:delta-core_2.12:2.4.0"
